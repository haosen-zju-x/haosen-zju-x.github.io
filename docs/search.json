[{"categories":["Algebra"],"content":"What’s next?\n— No.3 — Shihe asked me the following problem on October 23, 2022. After a while, we exchanged our proofs, which I felt faithfully reflected the differences in the way we do math.\nProblem [Existence of a suitable orthogonal projection]\nLet \\(L\\subset \\mathbb{R}^{n+l}\\) (\\(n,l\\ge 1\\)) be an \\(n\\)-dimensional subspace and \\(\\{v_1,\\cdots,v_{n+l}\\}\\) a basis of \\(\\mathbb{R}^{n+l}\\). Show that there exist \\(1\\le j_1\u003c\\cdots\u003cj_n\\le n+l\\) such that the restriction \\(P_{j_1,\\cdots,j_n}|_L:L\\to \\mathbb{R}^{n+l}\\) is injective (and hence induces an isomphism), where \\(P_{j_1,\\cdots,j_n}\\) denotes the orthogonal projection of \\(\\mathbb{R}^{n+l}\\) onto \\(\\text{span}\\{v_{j_1},\\cdots,v_{j_n}\\}\\).\nProof I [Haosen]\nThe orthogonal complement of the kernel of \\(P_{j_1,\\cdots,j_n}|_L\\) is \\[\\begin{align*} \\ker(P_{j_1,\\cdots,j_n}|_L)^{\\perp} \u0026=\\left(\\ker(P_{j_1,\\cdots,j_n})\\cap L\\right)^{\\perp}\\\\ \u0026=\\left(\\text{span}(\\{v_{j_1},\\cdots,v_{j_n}\\})^{\\perp}\\cap L\\right)^{\\perp}\\\\ \u0026=\\text{span}(\\{v_{j_1},\\cdots,v_{j_n}\\})+L^{\\perp}. \\end{align*}\\] Therefore \\(P_{j_1,\\cdots,j_n}|_L\\) is injective iff \\(\\text{span}(\\{v_{j_1},\\cdots,v_{j_n}\\})+L^{\\perp}=\\mathbb{R}^{n+l}\\).\nLet \\(\\{w_1,\\cdots,w_l\\}\\) be a basis of the \\(l\\)-dimensional subspace \\(L^{\\perp}\\). There exists \\(A\\in M_{(n+l)\\times l}(\\mathbb{R})\\) of rank \\(l\\) such that \\[ (w_1\\ \\cdots\\ w_l)=(v_1\\ \\cdots\\ v_{n+l})A. \\] Now we note that there exists a sequence of elementary column operations that transforms \\(A\\) into a matrix with exactly \\(n\\) zero rows, in other words, there exists \\(Q\\in GL_{l}(\\mathbb{R})\\) such that \\(AQ\\) has exactly \\(n\\) zero rows, with the other \\(l\\) nonzero rows being linearly independent. We claim that the labels of the zero rows, denoted by \\(1\\le j_1\u003c\\cdots\u003cj_n\\le n+l\\), will fulfill the proof. For clarity, denote by \\(1\\le i_1\u003c\\cdots\u003ci_l\\le n+l\\) the labels of the nonzero rows.\nIn fact, \\(L^{\\perp}=\\text{span}(\\{w_1,\\cdots,w_l\\})=\\) the column space of the matrix \\((w_1\\ \\cdots\\ w_l)=\\) the column space of the matrix \\((w_1\\ \\cdots\\ w_l)Q=\\) the column space of the matrix \\((v_1\\ \\cdots\\ v_{n+l})AQ=\\text{span}(\\{v_{i_1},\\cdots,v_{i_l}\\})\\). Therefore, \\(\\text{span}(\\{v_{j_1},\\cdots,v_{j_n}\\})+L^{\\perp}=\\text{span}(\\{v_1,\\cdots,v_{n+l}\\})=\\mathbb{R}^{n+l}\\). \\(\\blacksquare\\)\nProof II [Shihe]\nShehe’s proof is more geometrically intuitive. For each \\(1\\le k\\le n+l\\), take a nonzero vector \\(w_k\\in \\mathbb{R}^{n+l}\\) such that \\(\\text{span}(\\{w_k\\})=\\text{span}(\\{v_1,\\cdots,v_{n+l}\\}\\setminus\\{v_k\\})^{\\perp}\\). We claim that \\(w_1,\\cdots,w_{n+l}\\) are linearly independent.\nIn fact, if \\(\\sum_{k=1}^{n+l}\\lambda_k w_k=0\\) (\\(\\lambda_1,\\cdots,\\lambda_{n+l}\\in \\mathbb{R}\\)), then by applying \\(\\langle \\cdot,v_k\\rangle\\) to both sides we get \\(\\lambda_k\\langle w_k,v_k\\rangle=0\\) (\\(k=1,\\cdots,n+l\\)). Clearly \\(\\langle w_k,v_k\\rangle\\neq 0\\), because otherwise \\(w_k\\) is orthogonal to every vector in the basis \\(\\{v_1,\\cdots,v_{n+l}\\}\\) and hence must be zero, contradiction. Thus \\(\\lambda_k=0\\ (k=1,\\cdots,n+l)\\), showing that \\(w_1,\\cdots,w_{n+l}\\) are linearly independent.\nSince \\(\\dim L=n\u003cn+l\\), there exists some \\(w_{k_1}\\) that is not in \\(L\\). The orthogonal projection of \\(\\mathbb{R}^{n+l}\\) along \\(\\text{span}(\\{w_{k_1}\\})\\), denoted by \\(P_{w_{k_1}}:\\mathbb{R}^{n+l}\\to \\mathbb{R}^{n+l}\\), induces an isomorphism when restricted to \\(L\\), as \\(\\ker(P_{w_{k_1}}|_L)=\\text{span}(\\{w_{k_1}\\})\\cap L=0\\). Moreover, \\[ \\text{Im}(P_{w_{k_1}})=\\ker(P_{w_{k_1}})^{\\perp}=\\text{span}(\\{w_{k_1}\\})^{\\perp}=\\text{span}(\\{v_1,\\cdots,v_{n+l}\\}\\setminus\\{v_{k_1}\\}). \\]\nIf \\(l=1\\), we’re done. If \\(l\\ge 2\\), then \\(\\dim P_{w_{k_1}}(L)=n\u003cn+l-1\\) and so there exists \\(k_2\\neq k_1\\) such that \\(w_{k_2}\\notin P_{w_{k_1}}(L)\\). The orthogonal projection of \\(\\text{Im}(P_{k_1})\\) along \\(\\text{span}(\\{w_{k_2}\\})\\), denoted by \\(P_{w_2}:\\text{Im}(P_{w_1})\\to \\text{Im}(P_{w_1})\\), induces an isomorphism when restricted to \\(P_{w_{k_1}}(L)\\), as \\(\\ker(P_{w_{k_2}}|_{P_{w_{k_1}}(L)})=\\text{span}(\\{w_{k_2}\\})\\cap P_{w_1}(L)=0\\). Moreover, \\[ \\text{Im}(P_{w_{k_2}})=\\ker(P_{w_{k_2}})^{\\perp}=\\text{span}(\\{w_{k_2}\\})^{\\perp}=\\text{span}(\\{v_1,\\cdots,v_{n+l}\\}\\setminus\\{v_{k_1},v_{k_2}\\}). \\] Continue this process inductively until we get \\(P_{w_l}\\). Then \\[ P:\\mathbb{R}^{n+l}\\to \\mathbb{R}^{n+l}\\quad P(v):=P_{w_l}\\circ\\cdots\\circ P_{w_2}\\circ P_{w_1}(v) \\] is a well-defined orthogonal projection of \\(\\mathbb{R}^{n+l}\\) on \\(\\text{span}(\\{v_1,\\cdots,v_{n+l}\\}\\setminus\\{v_{k_1},\\cdots,v_{k_l}\\})\\), fulfilling the proof. \\(\\blacksquare\\)\n— No.2 — In early February 2023, I asked myself the following seemingly naive question.\nProblem [The Gramian determines the shape]\nLet \\(\\{v_1,\\cdots,v_s\\}\\) and \\(\\{w_1,\\cdots,w_s\\}\\) be two subsets of \\(\\mathbb{R}^n\\). Show that there exists \\(A\\in O(n)\\) such that \\(Av_i=w_i\\ (1\\le i\\le s)\\) iff \\(\\langle v_{i}, v_{j}\\rangle=\\langle w_{i}, w_{j}\\rangle\\ (1\\le i,j\\le s)\\), i.e., the two Gramians are equal.\n(Similarly, if \\(\\{v_1,\\cdots,v_s\\}\\) and \\(\\{w_1,\\cdots,w_s\\}\\) are two subsets of \\(\\mathbb{C}^n\\), then there exists \\(A\\in U(n)\\) such that \\(Av_i=w_i\\ (1\\le i\\le s)\\) iff \\(\\langle v_{i}, v_{j}\\rangle=\\langle w_{i}, w_{j}\\rangle\\ (1\\le i,j\\le s)\\), i.e., the two Gramians are equal.)\nProof [Haosen] We summarize the idea of proving \\((\\Leftarrow)\\) as follows. Given the data \\(\\langle v_i,v_j \\rangle\\ (1\\le i,j\\le s)\\), we may focus on a maximal linearly independent subset of \\(\\{v_1,\\cdots,v_s\\}\\) to study the shape formed by these \\(s\\) vectors in \\(\\mathbb{R}^n\\). Suppose that \\(\\{v_{k_1},\\cdots,v_{k_r}\\}\\) is a maximal linearly independent subset of \\(\\{v_1,\\cdots,v_s\\}\\), then \\(\\{w_{k_1},\\cdots,w_{k_r}\\}\\) is automatically a maximal linearly independent subset of \\(\\{w_1,\\cdots,w_s\\}\\). Perform Gram-Schmidt on them simultaneously and extend the resulted orthonormal subsets to two orthonormal bases for \\(\\mathbb{R}^n\\). The associated change of coordinates matrix then fulfills the proof. (The Gram-Schmidt process can be embodied by QR decomposition.)\n\\((\\Rightarrow)\\): Obvious. \\[ \\begin{align*} G(w_1,\\cdots,w_s)\u0026=(w_{1}\\ \\cdots\\ w_{s})^{T}(w_{1}\\ \\cdots\\ w_{s})\\\\ \u0026=(v_{1}\\ \\cdots\\ v_{s})^{T}A^TA(v_{1}\\ \\cdots\\ v_{s})\\\\ \u0026=(v_{1}\\ \\cdots\\ v_{s})^{T}(v_{1}\\ \\cdots\\ v_{s})=G(v_1,\\cdots,v_s).\\end{align*} \\] \\((\\Leftarrow)\\): Note that \\[\\begin{align*}\\text{rank}(v_{1}\\ \\cdots\\ v_{s})\u0026=\\text{rank}\\, G(v_1,\\cdots,v_{s})\\\\ \u0026=\\text{rank}\\, G(w_1,\\cdots,w_s)=\\text{rank}(w_{1}\\ \\cdots\\ w_{s})\\end{align*}\\] Denote \\(r:=\\text{rank}(v_{1}\\ \\cdots\\ v_{s})\\). Without loss of generality, assume that \\(v_1,\\cdots,v_r\\) are linearly independent. We claim that \\(w_1,\\cdots,w_r\\) are linearly independent as well. Indeed, \\[ \\begin{align*} \\text{Null}\\,(w_1\\ \\cdots\\ w_r)\u0026=\\text{Null}\\,(w_1\\ \\cdots\\ w_r)^T(w_1\\ \\cdots\\ w_r)\\\\ \u0026=\\text{Null}\\,(v_1\\ \\cdots\\ v_r)^T(v_1\\ \\cdots\\ v_r)=\\text{Null}\\,(v_1\\ \\cdots\\ v_r)=0. \\end{align*} \\] Therefore, there exist \\(B,C\\in M_{r\\times (s-r)}(\\mathbb{R})\\) such that \\[ \\begin{align*} (v_1\\ \\cdots\\ v_s)\u0026=(v_1\\ \\cdots\\ v_r)(I_r\\ |\\ B),\\\\ (w_1\\ \\cdots\\ w_s)\u0026=(w_1\\ \\cdots\\ w_r)(I_r\\ |\\ C). \\end{align*} \\] Denote \\(G:=G(v_1,\\cdots,v_r)=G(w_1,\\cdots,w_r)\\). Since \\(\\text{rank}(G)=\\text{rank}(v_1\\ \\cdots\\ v_r)=r\\), the matrix \\(G\\) is invertible. Thus we have \\[ \\begin{pmatrix} I_r\\\\\\hline B^T \\end{pmatrix}\\,G\\,(I_r\\ |\\ B)=\\begin{pmatrix} I_r\\\\\\hline C^T \\end{pmatrix}\\,G\\,(I_r\\ |\\ C)\\implies GB=GC\\implies B=C. \\] Now, it suffices to find some \\(A\\in O(n)\\) such that \\[ A(v_1\\ \\cdots\\ v_r)=(w_1\\ \\cdots\\ w_r) \\] By QR decomposition, we have \\[ (v_1\\ \\cdots\\ v_r)=Q_1R_1,\\quad (w_1\\ \\cdots\\ w_r)=Q_2R_2 \\] where \\(R_i\\in M_{r\\times r}(\\mathbb{R})\\) is an upper triangular matrix with positive diagonal entries and \\(Q_i\\in M_{n\\times r}(\\mathbb{R})\\) satisfies \\(Q_i^TQ_i=I_r\\) (semi-orthogonal). Thus we have \\[ (Q_1R_1)^TQ_1R_1=(Q_2R_2)^TQ_2R_2\\implies R_1^TR_1=R_2^TR_2. \\] By the uniqueness of Cholesky decomposition for positive-definite matrices, we have \\(R_1=R_2\\). Indeed, \\(R_1R_2^{-1}=(R_1^{T})^{-1}R_2^T\\) is upper triangular and lower triangular, and hence a diagonal matrix, denoted by \\(D\\). Thus we have \\[ R_1=DR_2,\\ R_2^T=R_1^TD\\implies D=I_r\\implies R_1=R_2. \\]\nTherefore, it suffices to find some \\(A\\in O(n)\\) such that \\[ AQ_1=Q_2. \\] Since the columns of \\(Q_i\\) forms an orthonormal subset of \\(\\mathbb{R}^n\\) and thus extends to an orthonormal basis for \\(\\mathbb{R}^n\\), there exists \\(\\widetilde{Q}_i\\in O(n)\\) such that \\(\\widetilde{Q}_i=(Q_i\\ |\\ X_i)\\) for some \\(X_i\\in M_{n\\times (n-r)}(\\mathbb{R})\\). Define \\(A:=\\widetilde{Q}_2\\widetilde{Q}_1^{-1}\\). Then \\(A\\in O(n)\\) and \\(AQ_1=Q_2\\), as desired. \\(\\blacksquare\\)\n— No.1 — The next was one of the problems in my entrance examination of École Polytechnique, in November 2021. It estimates the size of a set of unit vectors that are “almost orthonormal”.\nProblem [Almost orthonormal]\nShow that if \\(v_1,\\cdots,v_m\\) are \\(m\\) unit vectors in \\(\\mathbb{C}^n\\) such that \\(|\\langle v_i,v_j \\rangle|\\le \\frac{1}{2\\sqrt{n}}\\) for any \\(i\\neq j\\), then \\(m\u003c2n\\).\nProof [Haosen, under the guidance of the examiner]\nLet \\(G:=G(v_1,\\cdots,v_m)\\) be the Gramian, i.e., \\(G(i,j)=\\langle v_i,v_j \\rangle\\) for \\(1\\le i,j\\le m\\). Define \\(H:=G-I_m\\). Since \\(H\\) is Hermitian, we have \\[ \\begin{align*} \\text{tr}(H^2)\u0026=\\text{tr}(H^*H)\\\\ \u0026=\\sum_{i,j=1}^{m}|H(i,j)|^2\\\\ \u0026=\\sum_{1\\le i\\neq j\\le m}|\\langle v_i,v_j\\rangle|^2\\\\ \u0026\\le (m^2-m)\\cdot (\\tfrac{1}{2\\sqrt{n}})^2=\\frac{m^2-m}{4n}. \\end{align*} \\] On the other hand, since \\(G\\) is positive semi-definite, \\(G\\) has \\(r:=\\text{rank}(G)=\\text{rank}(v_1\\ \\cdots\\ v_m)\\le n\\) positive eigenvalues, and the other \\(m-r\\) eigenvalues of \\(G\\) are all zero. (In fact, we only use the latter.) Consequently, the eigenvalues of \\(H\\) are \\(\\underbrace{\\lambda_1,\\cdots,\\lambda_r}_{\\in (-1,+\\infty)},\\underbrace{-1,\\cdots,-1}_{m-r}\\), and the eigenvalues of \\(H^2\\) are \\(\\underbrace{\\lambda_1^2,\\cdots,\\lambda_r^2}_{\\in [0,+\\infty)},\\underbrace{1,\\cdots,1}_{m-r}\\). Therefore, \\[ \\text{tr}(H^2)=\\sum_{i=1}^{r}\\lambda_i^2+(m-r)\\ge m-n. \\] Combining the two estimates, we conclude that \\[ m-n\\le \\frac{m^2-m}{4n}, \\] from which \\(m\u003c2n\\) follows. \\(\\blacksquare\\)\n","description":"","tags":["Undergraduate","Linear Algebra","Problem Solving"],"title":"Problems in Linear Algebra","uri":"/posts/linear-algebra-problem-solving/"},{"categories":["Topology"],"content":" The Poincaré Lemma for Compactly Supported Cohomology Let \\(M\\) be a smooth manifold. Then the product manifold \\(M\\times \\mathbb{R}^1\\) is a smooth manifold as well, and the projection \\(\\pi:M\\times \\mathbb{R}^1\\to M\\) is a smooth map. The pullback \\(\\pi^*:\\Omega^*(M)\\to \\Omega^*(M\\times \\mathbb{R}^1)\\) [1] does not map \\(\\Omega_c^*(M)\\) into \\(\\Omega_c^*(M\\times \\mathbb{R}^1)\\), so instead we consider the pushforward known as integration along the fiber \\[ \\begin{equation*} \\pi_*:\\Omega_c^*(M\\times \\mathbb{R}^1)\\to \\Omega_c^{*-1}(M)\\quad \\begin{cases} f(x,t)\\pi^*\\phi\\mapsto 0\\\\ f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\phi\\mapsto \\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi \\end{cases} \\end{equation*} \\] where \\(\\phi\\in \\Omega^*(M)\\) and \\(f\\in C_c^{\\infty}(M\\times \\mathbb{R};\\mathbb{R})\\). (These two types of elements in \\(\\Omega_c^*(M\\times \\mathbb{R}^1)\\) will soon be revisited.) It’s quick to check that \\(\\pi_*\\) is a chain map. We will show that the induced map \\(\\pi_*:H_c^*(M\\times \\mathbb{R}^1)\\to H_c^{*-1}(M)\\) is an isomorphism.\nTake \\(e=e(t)\\mathrm{d}{t}\\in \\Omega_c^1(\\mathbb{R}^1)\\) such that \\(\\displaystyle\\int_{\\mathbb{R}^1} e=1\\). Define \\[ \\begin{equation*} e_*:\\Omega_c^*(M)\\to \\Omega_c^{*+1}(M\\times \\mathbb{R}^1)\\quad \\psi\\mapsto e(t)\\mathrm{d}{t}\\wedge\\pi^*\\psi \\end{equation*} \\] where the map \\(t\\mapsto e(t)\\) has been identified with the composition \\((x,t)\\mapsto t\\mapsto e(t)\\). It’s quick to check that \\(e_*\\) is a chain map, and \\(\\pi_*\\circ e_*=\\text{id}\\) on \\(\\Omega_c^*(M)\\). We will show that there is a chain homotopy \\(K\\) connecting \\(e_*\\circ \\pi_*\\) and \\(\\text{id}\\) on \\(\\Omega_c^*(M\\times \\mathbb{R}^1)\\), so that the induced map \\(e_*:H_c^{*}(M)\\to H_c^{*+1}(M\\times \\mathbb{R}^1)\\) is the inverse of \\(\\pi_*:H_c^*(M\\times \\mathbb{R}^1)\\to H_c^{*-1}(M)\\).\nWe shall construct the desired chain homotopy \\(K:\\Omega_c^*(M\\times \\mathbb{R}^1)\\to \\Omega_c^{*-1}(M\\times \\mathbb{R}^1)\\) from the basic relation \\[ \\begin{equation*} \\text{id}-e_*\\circ \\pi_*=\\mathrm{d}K+K \\mathrm{d} \\end{equation*} \\] To proceed, interpret this relation on the aforementioned two types of elements in \\(\\Omega_c^*(M\\times \\mathbb{R}^1)\\), and be reminded that computations will be done w.r.t. some specific local coordinates.\nFor \\(f(x,t)\\pi^*\\phi\\), we require \\[ \\begin{equation*} f(x,t)\\pi^*\\phi=\\mathrm{d}K(f(x,t)\\pi^*\\phi)+K \\left[\\left(\\displaystyle\\sum_i \\dfrac{\\partial f}{\\partial x^i}(x,t)\\mathrm{d}{x^i}+\\dfrac{\\partial f}{\\partial t}(x,t)\\mathrm{d}{t}\\right)\\wedge \\pi^*\\phi+f(x,t)\\pi^*\\mathrm{d}{\\phi}\\right] \\end{equation*} \\] For \\(f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\phi\\), we require \\[ \\begin{align*} \u0026f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\phi-e(t)\\mathrm{d}{t}\\wedge\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right]\\\\ \u0026=\\mathrm{d}K(f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\phi)+K \\left[-\\displaystyle\\sum_i \\dfrac{\\partial f}{\\partial x^i}(x,t)\\mathrm{d}{t}\\wedge\\mathrm{d}{x^i}\\wedge\\pi^*\\phi-f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\mathrm{d}{\\phi}\\right] \\end{align*} \\] We observe that when \\(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t=0\\), or equivalently, \\(f\\in \\dfrac{\\partial }{\\partial t}(C_c^{\\infty}(M\\times \\mathbb{R}^1))\\), the two requirements become very close. An immediate guess follows: \\[ \\begin{equation*} K_1(f(x,t)\\pi^*\\phi)=0,\\quad K_1(f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\phi)=\\left(\\displaystyle\\int_{-\\infty}^{t} f(x,t) \\,\\mathrm{d}t\\right)\\pi^*\\phi \\end{equation*} \\] whenever \\(\\phi\\in \\Omega^*(M)\\) and \\(f\\in C_c^*(M\\times \\mathbb{R}^1)\\). While \\(K_1\\) solves the first requirement, it does not reconcile with the second: \\[ \\begin{align*} \u0026\\mathrm{d}K_1(f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\phi)+K_1 \\left[-\\displaystyle\\sum_i \\dfrac{\\partial f}{\\partial x^i}(x,t)\\mathrm{d}{t}\\wedge\\mathrm{d}{x^i}\\wedge\\pi^*\\phi-f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\mathrm{d}{\\phi}\\right]\\\\ =\u0026\\mathrm{d}\\left[\\left(\\displaystyle\\int_{-\\infty}^{t} f(x,t) \\,\\mathrm{d}t\\right)\\pi^*\\phi\\right]-\\displaystyle\\sum_i \\left(\\displaystyle\\int_{-\\infty}^{t} \\dfrac{\\partial f}{\\partial x^i}(x,t) \\,\\mathrm{d}t\\right)\\mathrm{d}{x^i}\\wedge \\pi^*\\phi-\\left(\\displaystyle\\int_{-\\infty}^{t} f(x,t) \\,\\mathrm{d}t\\right)\\pi^*\\mathrm{d}{\\phi}\\\\ =\u0026f(x,t)\\mathrm{d}{t}\\wedge \\pi^*\\phi \\end{align*} \\] However, the computation also indicates that we are not far away from success, with only one term involving \\(e=e(t)\\mathrm{d}{t}\\) missing.\nAs a remedy, consider \\(K_2=K-K_1\\). It suffices to construct \\(K_2\\) in the same fashion:\nFor \\(f(x,t)\\pi^*\\phi\\), we require \\[ \\begin{equation*} 0=\\mathrm{d}K_2(f(x,t)\\pi^*\\phi)+K_2 \\left[\\left(\\displaystyle\\sum_i \\dfrac{\\partial f}{\\partial x^i}(x,t)\\mathrm{d}{x^i}+\\dfrac{\\partial f}{\\partial t}(x,t)\\mathrm{d}{t}\\right)\\wedge \\pi^*\\phi+f(x,t)\\pi^*\\mathrm{d}{\\phi}\\right] \\end{equation*} \\] For \\(f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\phi\\), we require \\[ \\begin{align*} \u0026-e(t)\\mathrm{d}{t}\\wedge\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right]\\\\ \u0026=\\mathrm{d}K_2(f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\phi)+K_2 \\left[-\\displaystyle\\sum_i \\dfrac{\\partial f}{\\partial x^i}(x,t)\\mathrm{d}{t}\\wedge\\mathrm{d}{x^i}\\wedge\\pi^*\\phi-f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\mathrm{d}{\\phi}\\right] \\end{align*} \\] It is again natural to set \\(K_2(f(x,t)\\pi^*\\phi)=0\\), and so the first requirement simplifies to \\[ \\begin{equation*} K_2 \\left(\\dfrac{\\partial f}{\\partial t}(x,t)\\mathrm{d}{t}\\wedge \\pi^*\\phi\\right)=0 \\end{equation*} \\] Now we focus on the second requirement. Note that \\[ \\begin{align*} \u0026\\hphantom{=}e(t)\\mathrm{d}{t}\\wedge\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right]\\\\ \u0026=\\mathrm{d}\\left(\\displaystyle\\int_{-\\infty}^{t} e(t) \\,\\mathrm{d}t\\right)\\wedge\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right]+\\left(\\displaystyle\\int_{-\\infty}^{t} e(t) \\,\\mathrm{d}t\\right)\\mathrm{d}\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right]\\\\ \u0026\\hphantom{=\\mathrm{d}\\left(\\displaystyle\\int_{-\\infty}^{t} e(t) \\,\\mathrm{d}t\\right)\\wedge\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right]}-\\left(\\displaystyle\\int_{-\\infty}^{t} e(t) \\,\\mathrm{d}t\\right)\\mathrm{d}\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right]\\\\ \u0026=\\mathrm{d}\\left\\{\\left(\\displaystyle\\int_{-\\infty}^{t} e(t) \\,\\mathrm{d}t\\right)\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right]\\right\\}\\\\ \u0026\\hphantom{=}-\\left(\\displaystyle\\int_{-\\infty}^{t} e(t) \\,\\mathrm{d}t\\right)\\pi^*\\left[\\displaystyle\\sum_i \\left(\\displaystyle\\int_{-\\infty}^{\\infty} \\dfrac{\\partial f}{\\partial x^i}(x,t) \\,\\mathrm{d}t\\right)\\mathrm{d}{x^i}\\wedge \\phi+\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\mathrm{d}{\\phi}\\right] \\end{align*} \\] An immediate guess follows: \\[ \\begin{equation*} K_2(f(x,t)\\mathrm{d}{t}\\wedge \\pi^*\\phi)=-\\left(\\displaystyle\\int_{-\\infty}^{t} e(t) \\,\\mathrm{d}t\\right)\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right] \\end{equation*} \\] which indeed solves the second requirement, and together with \\(K_2(f(x,t)\\pi^*\\phi)=0\\), solves the first, since \\[ \\begin{equation*} \\displaystyle\\int_{-\\infty}^{\\infty} \\dfrac{\\partial f}{\\partial t}(x,t) \\,\\mathrm{d}t=0 \\end{equation*} \\]\nConclusion: The map \\(K:\\Omega_c^{*}(M\\times \\mathbb{R}^1)\\to \\Omega_c^{*-1}(M\\times \\mathbb{R}^1)\\) defined by \\[ \\begin{equation*} \\begin{cases} f(x,t)\\pi^*\\phi\\mapsto 0\\\\ f(x,t)\\mathrm{d}{t}\\wedge\\pi^*\\phi\\mapsto \\left(\\displaystyle\\int_{-\\infty}^{t} f(x,t) \\,\\mathrm{d}t\\right)\\pi^*\\phi-\\left(\\displaystyle\\int_{-\\infty}^{t} e(t) \\,\\mathrm{d}t\\right)\\pi^*\\left[\\left(\\displaystyle\\int_{-\\infty}^{\\infty} f(x,t) \\,\\mathrm{d}t\\right)\\phi\\right] \\end{cases} \\end{equation*} \\] is a chain homotopy connecting \\(e_*\\circ \\pi_*\\) and \\(\\text{id}\\) on \\(\\Omega_c^*(M\\times \\mathbb{R}^1)\\), and consequently the maps \\[ \\begin{equation*} H_c^{*+1}(M\\times \\mathbb{R})\\begin{matrix}\\xrightarrow{\\pi_*}\\\\ \\xleftarrow[e_*]{}\\end{matrix}H_c^*(M) \\end{equation*} \\] are isomorphisms.\nAs a corollary, for each positive integer \\(n\\), there holds \\[ \\begin{equation*} H_c^*(\\mathbb{R}^n)=\\begin{cases} \\mathbb{R}, \u0026\\text{in dimension $n$}\\\\ 0, \u0026\\text{elsewhere} \\end{cases} \\end{equation*} \\] where the isomorphism \\(H_c^*(\\mathbb{R}^n)\\xrightarrow{\\cong}\\mathbb{R}\\) is given by iterated \\(\\pi_*\\), i.e., by integration over \\(\\mathbb{R}^n\\), thanks to Fubini’s theorem. Besides, by iterating \\(e_*\\), we see that a generator of \\(H_c^n(\\mathbb{R}^n)\\) is represented by a bump \\(n\\)-form \\(\\alpha=\\alpha(x)\\mathrm{d}{x^1}\\wedge\\cdots\\wedge \\mathrm{d}{x^n}\\) with \\(\\displaystyle\\int_{\\mathbb{R}^n} \\alpha=1\\), whose support can be made as small as possible.\n[To be explicit, if \\(\\phi\\in \\Omega^r(M)\\) is represented as \\(\\sum_{i_1\u003c\\cdots\u003ci_r}\\phi_{i_1\\cdots i_r}(x)\\mathrm{d}{x^{i_1}}\\wedge\\cdots\\wedge \\mathrm{d}{x^{i_r}}\\) w.r.t. some chosen local coordinates on \\(M\\), then \\(\\pi^*\\phi\\in \\Omega^r(M\\times \\mathbb{R})\\) is simply represented as \\(\\sum_{i_1\u003c\\cdots\u003ci_r}\\phi_{i_1\\cdots i_r}\\circ \\pi(x,t)\\mathrm{d}{x^{i_1}}\\wedge\\cdots\\wedge \\mathrm{d}{x^{i_r}}\\) w.r.t. the associated local coordinates on \\(M\\times \\mathbb{R}^1\\).]↩︎\n","description":"Explain the ideas behind the construction of the chain homotopy in the proof of the Poincaré lemma for compactly supported cohomology (cf. Bott-Tu, Differential Forms in Algebraic Topology).","tags":["Algebraic Topology","Differentiable Manifolds"],"title":"Poincaré Duality","uri":"/posts/poincare-duality/"},{"categories":["Geometry"],"content":"Part I Let \\(M\\) be a smooth \\(m\\)-manifold and \\(p\\in M\\). We will define the tangent space and the cotangent space of \\(M\\) at \\(p\\).\nTangent Space \\(T_pM\\) — The Geometric Approach Choose a local chart \\((U,\\varphi)\\) centered at \\(p\\).\nSet \\(C_p:=\\{\\alpha\\in C^{\\infty}(I;M) \\,|\\, \\text{$I$ is an open interval containing $0$}, \\alpha(0)=p\\}\\). Define \\(T_pM:=C_p/\\sim\\), where \\(\\sim\\) is an equivalence relation on \\(C_p\\) defined by \\(\\alpha\\sim \\beta:\\iff (\\varphi\\circ \\alpha)'(0)=(\\varphi\\circ \\beta)'(0)\\). If \\((V,\\psi)\\) is another local chart centered at \\(p\\), then we have \\((\\psi\\circ \\alpha)'(0)=(\\psi\\circ \\varphi^{-1})'(0) (\\varphi\\circ \\alpha)'(0)\\). Therefore the definition of the equivalence relation \\(\\sim\\) does not depend on the choice of the local chart, neither does the definition of \\(T_pM\\). The 1-1 correspondence \\(T_pM\\ni [\\alpha]\\mapsto (\\varphi\\circ \\alpha)'(0)\\in \\mathbb{R}^m\\) induces an \\(m\\)-dimensional real vector space structure on \\(T_pM\\). The elements of \\(T_pM\\) are called tangent vectors, and \\(T_pM\\) is called the tangent space of \\(M\\) at \\(p\\). Denote by \\(\\{\\left.\\tfrac{\\partial }{\\partial x^1}\\right|_p, \\cdots, \\left.\\tfrac{\\partial }{\\partial x^m}\\right|_p\\}\\) the base of \\(T_pM\\) corresponding to \\(\\{e_1,\\cdots,e_m\\}\\) in the chosen local chart.\nRemark [Tangent vectors as directional derivatives] The following observation motivates the definition of cotangent vectors: we can view tangent vectors as operators taking directional derivatives of smooth functions. For every \\(\\gamma\\in C_p\\), whenever \\(f\\) is a real-valued \\(C^{\\infty}\\) function on an open neighborhood of \\(p\\), define \\[\\begin{equation*} [\\gamma]f:=D_{\\gamma}(f)=\\left.\\dfrac{\\mathrm{d}}{\\mathrm{d}t}\\right|_{t=0}(f\\circ \\gamma)(t). \\end{equation*}\\] To justify this definition we note that \\[\\begin{equation*} D_{\\gamma}(f)=\\nabla(f\\circ \\varphi^{-1})(0)\\cdot (\\varphi\\circ \\gamma)'(0), \\end{equation*}\\] which shows that \\(D_\\gamma\\) (taking derivatives along \\(\\gamma\\)) is completely determined by the equivalence class of \\(\\gamma\\), i.e., the tangent vector \\([\\gamma]\\). This identity also shows that \\[\\begin{equation*} \\left.\\dfrac{\\partial }{\\partial x^i}\\right|_p f=\\partial_i (f\\circ \\varphi^{-1})(0) \\end{equation*}\\] and moreover: \\(([\\alpha]+[\\beta])f=[\\alpha]f+[\\beta]f, (\\lambda[\\alpha])f=\\lambda([\\alpha]f)\\). On the other hand, we have: \\([\\gamma](f+g)=[\\gamma]f+[\\gamma]g, [\\gamma](\\lambda f)=\\lambda([\\gamma]f)\\), and \\([\\gamma](fg)=([\\gamma]f)g(p)+f(p)([\\gamma]g)\\). (We intentionally omit the treatment of tangent spaces as so called derivations.)\nCotangent Space \\(T_p^*M\\) — The Algebraic Approach Set \\(F_p:=\\{(f,U) \\,|\\, \\text{$U$ is an open neighborhood of $p$}, f\\in C^{\\infty}(U;\\mathbb{R})\\}/\\sim\\), where the equivalence relation is as follows: \\((f,U)\\sim (g,V)\\) iff there exists an open neighborhood \\(W\\subset U\\cap V\\) such that \\(f|_W=g|_W\\). The elements of \\(F_p\\) are called germs (of the sheaf of smooth functions on \\(M\\)). In the space of germs at \\(p\\), define \\([f,U]+[g,V]:=[f+g,U\\cap V]\\) and \\([f,U]\\cdot [g,V]:=[fg,U\\cap V]\\). Then \\((F_p,+,\\cdot)\\) is a local ring whose unique maximal ideal is \\(\\mathfrak{m}_p:=\\{[f]\\in F_p \\,|\\, f(p) = 0\\}\\) and whose residue field is \\(\\mathbb{R}\\). Define the cotangent space of \\(M\\) at \\(p\\) to be \\(T_p^*M:=\\mathfrak{m}_p/\\mathfrak{m}_p^2\\).\nWe show that \\(T_p^*M\\) is naturally a real vector space of dimension \\(m\\). Let \\(x^1,\\cdots,x^m\\) be a local coordinate system centered at \\(p\\). One can show that \\[\\begin{equation*} \\mathfrak{m}_p=\\{[f]\\in F_p \\,|\\, \\exists [f_i]\\in F_p \\text{ s.t. } f= \\textstyle\\sum x^if_i\\}=\\langle [x^1],\\cdots,[x^m] \\rangle. \\end{equation*}\\] Consider the map \\[\\begin{equation*} \\theta:\\mathfrak{m}_p\\to \\mathbb{R}^n\\quad [\\textstyle\\sum x^if_i]\\mapsto (f_1(p),\\cdots,f_m(p)). \\end{equation*}\\] To verify that \\(\\theta\\) is well-defined, suppose that \\([\\sum x^if_i]=[\\sum x^ig_i]\\). In a suitable open neighborhood of \\(p\\), we have \\(f_i=g_i\\) on the subset \\((\\cap_{j\\neq i} \\{x_j=0\\})\\cap \\{x_i\\neq 0\\}\\). By continuity, we get \\(f_i(p)=g_i(p)\\), although \\([f_i]\\) may not equal to \\([g_i]\\). Therefore \\(\\theta\\) is a well-defined map, and moreover is a surjective homomorphism of \\(\\mathbb{R}\\)-modules. Now we conclude from \\(\\ker(\\theta)=\\mathfrak{m}_p^2\\) that \\(T_p^*M=\\mathfrak{m}_p/\\mathfrak{m}_p^2\\cong \\mathbb{R}^m\\) (as \\(\\mathbb{R}\\)-modules) and that \\(T_p^*M=\\text{span}\\{\\mathrm{d}x^1,\\cdots,\\mathrm{d}x^m\\}\\), where \\(\\mathrm{d}x^i:=[[x^i]]=[x^i]+\\mathfrak{m}_p^2\\). The elements of \\(T_p^*M\\) are called cotangent vectors.\nRemark [Duality] Suppose that the local coordinate system is associated with the local chart used before, i.e., \\(\\varphi=(x^1,\\cdots,x^m)\\), or equivalently \\(x^i\\circ \\varphi^{-1}(x_1,\\cdots,x_m)=x_i\\). For any \\([f]\\in \\mathfrak{m}_p\\), write \\(f=\\sum x^if_i\\), then by linearity and Leibniz’s rule we have \\(\\left.\\tfrac{\\partial }{\\partial x^j}\\right|_p f =\\sum_i [(\\left.\\tfrac{\\partial }{\\partial x^j}\\right|_px^i)f_i(p)+x^i(p)(\\left.\\tfrac{\\partial }{\\partial x^j}\\right|_p f_i)] =\\sum_i \\partial_j(x^i\\circ \\varphi^{-1})(0)f_i(p) =f_j(p)\\). More generally, \\[\\begin{equation*} [\\gamma]f=(\\varphi\\circ \\gamma)'(0)\\cdot\\theta([f]),\\quad \\forall [\\gamma]\\in T_pM. \\end{equation*}\\] Therefore we have a canonical pairing between \\(T_pM\\) and \\(T_p^*M\\): \\[\\begin{equation*} [\\gamma][[f]]:=[\\gamma]f,\\quad\\forall ([\\gamma],[[f]])\\in T_pM\\times T_p^*M. \\end{equation*}\\] Since \\(\\left.\\tfrac{\\partial }{\\partial x^i}\\right|_p \\mathrm{d}x^j = \\left.\\tfrac{\\partial }{\\partial x^i}\\right|_p x^j=\\partial_i(x^j\\circ \\varphi^{-1})(0)=\\delta_i^j\\), the canonical pairing is perfect, showing that the tangent space \\(T_pM\\) and the cotangent space \\(T_p^*M\\) are canonically dual to each other.\nPart II Coming soon…\n","description":"","tags":["Differentiable Manifolds"],"title":"Tangent Staffs","uri":"/posts/tangent/"},{"categories":["Geometry"],"content":"Coming soon…\n","description":"","tags":["Differential Geometry","Riemannian Geometry"],"title":"Riemann Curvature Tensor","uri":"/posts/curvature/"}]
